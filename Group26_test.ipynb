{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSC311 – Machine Learning 2019 – GROUP 26 HAND SHAPE RECOGNITION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 Testing and Results Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SOME INITIALISING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import train_svm\n",
    "import log_reg\n",
    "import train_nn\n",
    "\n",
    "data = np.genfromtxt('group26_test.csv',delimiter=\",\", dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X and y for test\n",
    "X_test = data[:,:-1]\n",
    "y_test = data[:,12288]\n",
    "\n",
    "# Scaling X\n",
    "X_test_scaled = (X_test / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = train_svm.getmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "svm_predictions = y_pred\n",
    "accuracy = svm_model.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is 91.33333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy * 100\n",
    "\n",
    "print(\"The overall accuracy is \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  1  1  3]\n",
      " [ 0 48  2  0  0  0]\n",
      " [ 0  3 44  2  0  1]\n",
      " [ 0  0  2 45  2  1]\n",
      " [ 0  0  0  3 46  1]\n",
      " [ 0  0  0  4  0 46]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "svm_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(svm_matrix) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        50\n",
      "           1       0.94      0.96      0.95        50\n",
      "           2       0.92      0.88      0.90        50\n",
      "           3       0.82      0.90      0.86        50\n",
      "           4       0.94      0.92      0.93        50\n",
      "           5       0.88      0.92      0.90        50\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       300\n",
      "   macro avg       0.92      0.91      0.91       300\n",
      "weighted avg       0.92      0.91      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 90.0 % Accuracy\n",
      "Class 1 has 96.0 % Accuracy\n",
      "Class 2 has 88.0 % Accuracy\n",
      "Class 3 has 90.0 % Accuracy\n",
      "Class 4 has 92.0 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Class \"+ str(i) + \" has \" +  str(svm_matrix[i][i]/50*100) +\" % Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = log_reg.getmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_model.predict(X_test_scaled)\n",
    "receive = y_pred\n",
    "accuracy = logistic_model.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is 80.33333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy * 100\n",
    "\n",
    "print(\"The overall accuracy is \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  2  0  2  3  1]\n",
      " [ 0 46  4  0  0  0]\n",
      " [ 5  1 41  1  1  1]\n",
      " [ 3  1  0 38  7  1]\n",
      " [ 2  0  1  3 39  5]\n",
      " [ 2  0  0  4  9 35]]\n"
     ]
    }
   ],
   "source": [
    "logistic_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(logistic_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        50\n",
      "           1       0.92      0.92      0.92        50\n",
      "           2       0.89      0.82      0.85        50\n",
      "           3       0.79      0.76      0.78        50\n",
      "           4       0.66      0.78      0.72        50\n",
      "           5       0.81      0.70      0.75        50\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       300\n",
      "   macro avg       0.81      0.80      0.80       300\n",
      "weighted avg       0.81      0.80      0.80       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 84.0 % Accuracy\n",
      "Class 1 has 92.0 % Accuracy\n",
      "Class 2 has 82.0 % Accuracy\n",
      "Class 3 has 76.0 % Accuracy\n",
      "Class 4 has 78.0 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Class \"+ str(i) + \" has \" +  str(logistic_matrix[i][i]/50*100) +\" % Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "nn_model = train_nn.getmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn_model.predict(X_test_scaled)\n",
    "neural_predictions = y_pred\n",
    "accuracy = nn_model.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is 37.333333333333336\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy * 100\n",
    "\n",
    "print(\"The overall accuracy is \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  2  0  0 32  0]\n",
      " [ 0 29  1  0 20  0]\n",
      " [ 0  4  7  0 39  0]\n",
      " [ 2  0  0 10 38  0]\n",
      " [ 0  0  0  0 50  0]\n",
      " [ 0  0  0  0 50  0]]\n"
     ]
    }
   ],
   "source": [
    "neural_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(neural_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.32      0.47        50\n",
      "           1       0.83      0.58      0.68        50\n",
      "           2       0.88      0.14      0.24        50\n",
      "           3       1.00      0.20      0.33        50\n",
      "           4       0.22      1.00      0.36        50\n",
      "           5       0.00      0.00      0.00        50\n",
      "\n",
      "   micro avg       0.37      0.37      0.37       300\n",
      "   macro avg       0.64      0.37      0.35       300\n",
      "weighted avg       0.64      0.37      0.35       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mansa/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 32.0 % Accuracy\n",
      "Class 1 has 57.99999999999999 % Accuracy\n",
      "Class 2 has 14.000000000000002 % Accuracy\n",
      "Class 3 has 20.0 % Accuracy\n",
      "Class 4 has 100.0 % Accuracy\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Class \"+ str(i) + \" has \" +  str(neural_matrix[i][i]/50*100) +\" % Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Relevant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing predictions of models for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsvm():\n",
    "    return svm_predictions\n",
    "\n",
    "def getlog():\n",
    "    return receive\n",
    "\n",
    "def getneural():\n",
    "    return neural_predictions\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
